\documentclass[11pt]{article}

\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}              
\usepackage{amsmath}               
\usepackage{amsfonts}              
\usepackage{amsthm}                
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{url}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{algpseudocode}
\usepackage[plain]{algorithm}
\usepackage{enumitem}
\usepackage{authblk}
\usepackage{tcolorbox}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{dsfont}
\usepackage{tikz}
\usetikzlibrary{quantikz}
%\usepackage[T1]{fontenc}
%\usepackage{libertine}
%\usepackage[libertine]{newtxmath}


\hypersetup{
	unicode = true,
	colorlinks = true,
	citecolor = blue,
	filecolor = blue,
	linkcolor = blue,
	urlcolor = blue,
	pdfstartview = {FitH},
}

% theorem environments
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{example}[theorem]{Example}
\newtheorem*{remark}{Remark}
\newtheorem{note}{Note}
\newtheorem*{problem}{Problem}
\newtheorem*{fact}{Fact}



\algrenewcommand{\Require}{\item[\textbf{Input:}]}
\algrenewcommand{\Ensure}{\item[\textbf{Output:}]}

\newcommand{\wrt}{\vdash} 
\newcommand{\tildO}{\tilde{O}}

% roman numerals
\newcommand{\romnum}[1]{\romannumeral #1}
\newcommand{\Romnum}[1]{\uppercase\expandafter{\romannumeral #1}}

\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}

\DeclareMathOperator{\fieldchar}{char} % characteristic of a field
\DeclareMathOperator{\groupofend}{End} % endomorphism ring
\DeclareMathOperator{\tr}{Tr} % finite field trace
\DeclareMathOperator{\gal}{Gal} % Galois group
\DeclareMathOperator{\order}{ord} % order of an element
\DeclareMathOperator{\lcm}{lcm} % least common multiple
\DeclareMathOperator{\divisor}{div} % divisor on a curve
\DeclareMathOperator{\supp}{supp} % support of a divisor
\DeclareMathOperator{\norm}{N} % norm
\DeclareMathOperator{\negl}{negl} % norm
\DeclareMathOperator{\res}{Res}
\DeclareMathOperator{\aut}{Aut}
\DeclareMathOperator{\minpoly}{minpoly}
\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\rev}{rev}
\DeclareMathOperator{\entpy}{H}
\let\hom\relax
\DeclareMathOperator{\hom}{Hom}
\DeclareMathOperator{\qft}{F}
\DeclareMathOperator{\E}{\mathbb{E}}


\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\let\ket\relax
\DeclarePairedDelimiter{\ket}{\lvert}{\rangle}
\let\bra\relax
\DeclarePairedDelimiter{\bra}{\langle}{\rvert}
\DeclarePairedDelimiter{\lrang}{\langle}{\rangle}
\DeclarePairedDelimiter{\opnorm}{\lVert}{\rVert}


\def\Q{\mathbb{Q}}
\def\C{\mathbb{C}}
\def\K{\mathbb{K}}
\def\N{\mathbb{N}}
\def\R{\mathbb{R}}
\def\Z{\mathbb{Z}}
\def\F{\mathbb{F}}
\def\P{\mathbb{P}}
\def\MM{\mathsf{M}}
\def\CC{\mathsf{C}}
\def\lwe{\mathsf{LWE}}
\def\edcp{\mathsf{EDCP}}
\def\gen{\mathsf{Gen}}
\def\enc{\mathsf{Enc}}
\def\dec{\mathsf{Dec}}
\def\X{\mathcal{X}}
\def\SX{\mathcal{S(X)}}
\def\U{\mathcal{U}}


\title{Efficient Quantum Public-Key Encryption \\ From Learning With Errors}

\author{
	%% Javad Oilskin\thanks{Department of Computer Science, Ryerson University,
	%% (\tt{javad.doliskani@ryerson.ca}).}
}

\date{}
\setlength{\parindent}{0pt}
\sloppy




\begin{document}
\maketitle





%% ///////////////////////////////////////////////////////



\section{Preliminaries}
\label{sec:preli}



\subsection{Quantum Computation}

Our notations for quantum information mostly follow those of \cite{watrous2018theory}. The classical state of a register $\mathsf{X}$ is represented by a finite alphabet, say $\Sigma$. If the registers $\mathsf{X}_1, \dots, \mathsf{X}_n$ are represented by alphabets $\Sigma_1, \dots, \Sigma_n$ then the classical state of the tuple $(\mathsf{X}_1, \dots, \mathsf{X}_n)$ is represented by $\Sigma_1 \times \cdots \times \Sigma_n$. The complex Euclidean space associated with the register $\mathsf{X}$ is denoted by $\C^\Sigma$. For a complex Euclidean space $\X$, denote the unit sphere in $\X$ by $\SX$. A linear operator $\rho$ acting on $\X$ is called a density operator if $\rho$ is positive semidefinite with trace equal to $1$. The quantum state of the register $\mathsf{X}$ is represented by the set of density operators $\text{D}(\X)$.

We will use the Dirac notation for the elements of $\SX$. In particular, we denote the column vector $x \in \SX$ by $\ket{x}$ and the row vector $x^*$ by $\bra{x}$. A state $\rho$ is called pure if it can be written as $\rho = \ket{x}\bra{x}$, in which case we will simply write the state as $\ket{x}$. By the spectral theorem, every state $\rho$ is a linear combination of pure states. Therefore, a quantum state can also be represented as a linear combination
\[ \sum_{x} \alpha_x \ket{x}, \hspace*{1mm} \sum_{x} \abs{\alpha_x}^2 = 1. \]
We shall alternate between these equivalent representations of quantum states throughout this paper. The density operator representation is particularly useful when the underlying quantum state is not completely known. For example if, we only know that the system is in the state $\ket{\psi_x}$ with probability $p_x$ then the state of the system is described by the density operator
\[ \rho = \sum_{x} p_x \ket{\psi_x}\bra{\psi_x} = \E_x \Big[ \ket{\psi_x} \bra{\psi_x} \Big]. \]
More, generally, the density operator corresponding to a probability distribution $\gamma: \SX \rightarrow [0, 1]$ is defined as
\[ \rho_\gamma = \int_{\ket{\phi} \in \SX} \ket{\phi}\bra{\phi} d\gamma(\ket{\phi}) = \E_{\ket{\phi} \in \gamma} \Big[ \ket{\phi}\bra{\phi} \Big]. \]
For quantum public-key cryptography we will need a formal notion of quantum state discrimination. In particular, we need to formally define the notion of computational (in)distinguishability of quantum states. For our purposes, it is more convenient to define computational distinguishability for probability distributions over quantum states. The following is adapted from \cite[\S 3.3]{watrous2009zero}.
\begin{definition}
    Let $\X$ be a complex Euclidean space, and let $\gamma, \mu: \SX \rightarrow [0, 1]$ be probability distributions. Then $\gamma$ is said to be $(s, \epsilon)$-distinguishable from $\mu$ if there is a quantum measurement circuit $Q$ of size $s$ such that
    \[ \Big| \Pr_{\rho \in \gamma}[Q(\rho) = 1] - \Pr_{\rho \in \mu}[Q(\rho) = 1] \Big| \ge \epsilon. \]
\end{definition} 
Two distributions $\gamma, \mu$ are $(s, \epsilon)$-indistinguishable if they are not $(s, \epsilon)$-distinguishable.
\begin{definition}
    For each $n \in \N$, let $\X_n$ be a complex Euclidean space and let $\gamma_n, \mu_n: \mathcal{S}(\X_n) \rightarrow [0, 1]$ be probability distributions. Then the two ensembles $\{ \gamma_n \}_{n \in \N}$ and $\{ \mu_n \}_{n \in \N}$ are said to be polynomially quantum indistinguishable if for all polynomially bounded functions $s, p: \N \rightarrow \N$, the distributions $\gamma_n$ and $\mu_n$ are $(s(n), 1 / p(n))$-indistinguishable for almost all $n \in \N$.
\end{definition}
Two ensembles are called quantum computationally indistinguishable if they are polynomially quantum indistinguishable. The advantage of a polynomial-time quantum algorithm $Q$ in distinguishing between the distributions $\gamma_n$ and $\mu_n$ is defined as
\[ \delta_Q(\gamma_n, \mu_n) = \Big| \Pr_{\rho \in \gamma_n}[Q(\rho) = 1] - \Pr_{\rho \in \mu_n}[Q(\rho) = 1] \Big|. \]
Two ensembles $\{ \gamma_n \}$ and $\{ \mu_n \}$ are then quantum computationally indistinguishable if $\delta_Q(\gamma_n, \mu_n) = \negl(n)$ for all such $Q$ and almost all $n$. 



\subsection{Error reduction}
\label{sec:err-red}

We can abstractly define the advantage of an algorithm $A$, regardless of $A$ being quantum or classical, in distinguishing between two probability distribution $P_1$ and $P_2$ as
\[ \delta_A(P_1, P_2) = \Big| \Pr_{x \in P_1}[A(x) = 1] - \Pr_{x \in P_2}[A(x) = 1] \Big|. \]
Two ensembles of distributions $\{ P_{1, n} \}$ and $\{ P_{2, n} \}$ are said to be polynomial-time indistinguishable if for any polynomial-time algorithm $A$ and any $\poly(n)$-bounded function $p$ we have $\delta_A(P_{1, n}, P_{2, n}) \le 1 / p(n)$ for large enough $n$. The following lemma follows from the triangle inequality.
\begin{lemma}[Hybrid lemma]
    \label{lem:hybrid}
    Let $P_1, \dots, P_k$ be a sequence of probability distributions. Assume that $\delta_A(P_1, P_k) \ge \epsilon$ for some polynomial-time algorithm $A$. Then $\delta_A(P_i, P_{i + 1}) \ge \epsilon / k$ for some $1 \le i < k$.
\end{lemma}
Suppose an algorithm $A$ can distinguish between two distributions $P_1$ and $P_2$ with non-negligible advantage. A common technique to amplify the distinguishing advantage of $A$ is to sample enough times from the input distribution and then decide based on majority. A brief description of this technique, which we shall use several times in this paper, is as follows. First, we need the following well-known tail inequality.
\begin{lemma}[Hoeffding]
    \label{lem:hoeffding}
    Let $X_1, \dots, X_n$ be independent random variables with $X_i \in [a_i, b_i]$, and let $S = X_1, \cdots + X_n$. Then
    \begin{align*}
        \Pr[S - \E[S] \ge t] & \le e^{-2t^2 / \sum_i^n (b_i - a_i)^2}, \text{ and} \\
        \Pr[S - \E[S] \le -t] & \le e^{-2t^2 / \sum_i^n (b_i - a_i)^2}.
    \end{align*}
\end{lemma}
Now, assume $\delta_A(P_1, P_2) \ge 1 / p(n)$ for some polynomial $p(n)$, and let $P$ be the input distribution. Draw $m = 2np(n)^2$ samples from $P$, and let $X_i$ be a random variable representing the output of $A$ on input the $i$-th sample. Here, $X_i = 0$ (resp., $X_i = 1$) means $A$ has recognized the $i$-th sample to be from $P_1$ (resp., $P_2$). Let $S = X_1 + \cdots + X_m$. If $P = P_2$ then from the bound on $\delta_A$ we have $\E[S] \ge m / 2 + np(n)$. By Hoeffdings's inequality,
\begin{align*}
    \Pr\Big[ S \le \frac{1}{2} (m + np(n)) \Big]
    & = \Pr\Big[ S - \frac{m}{2} - np(n) \le -\frac{1}{2}np(n) \Big] \\
    & \le \Pr\Big[ S - \E[S] \le -\frac{1}{2}np(n) \Big] \\
    & \le e^{-n / 4}.
\end{align*}
Similarly, if $P = P_1$ then
\begin{align*}
    \Pr\Big[ S \ge \frac{1}{2} (m - np(n)) \Big]
    & \le \Pr\Big[ S - \E[S] \ge \frac{1}{2}np(n) \Big] \\
    & \le e^{-n / 4}.
\end{align*}
Therefore, by running $A$ on $m$ samples and counting the number of $1$'s we can tell, with probability exponentially close to $1$, whether $P = P_1$ or $P = P_2$.



\subsection{Learning With Errors}

In what follows, we briefly review the Learning With Error and the Extrapolated Dihedral Coset problems. Let $n \ge 1$, and $q = q(n) \ge 2$ be integers, and let $\chi$ be a probability distribution over $\Z$. For a random fixed $\bm{s} \in \Z_q^n$, denote by $A_{\bm{s}, \chi}$ the probability distribution over $\Z_q^n \times \Z_q$ defined as follows: choose $\bm{a} \in \Z_q^n$ uniformly at random, choose $e$ from according to $\chi$ and output  $(\bm{a}, \lrang{\bm{a}, \bm{s}} + e)$.
\begin{definition}[LWE, Search]
The search-$\lwe_{n, q, \chi}$ is the problem of recovering $\bm{s}$ given samples from the distribution $A_{\bm{s}, \chi}$. An algorithm $Q$ is said to solve $\lwe_{n, q, \chi}$ if $Q$  outputs $\bm{s}$ with probability at least $1 / \poly(n\log q)$ and has running time at most $\poly(n \log q)$.
\end{definition}
\begin{definition}[LWE, Decision]
    The decision-$\lwe_{n, q, \chi}$ problem is to distinguish between the distribution $A_{\bm{s}, \chi}$ and the uniform distribution over $\Z_q^n \times \Z_q$. An algorithm $Q$ is said to solve the desicion-$\lwe_{n, q, \chi}$ if it succeeds with advantage at least $1 / \poly(n\log q)$ and has running time at most $\poly(n\log q)$. 
\end{definition}
The distribution $\chi$ is called the error distribution and is usually chosen to be $\mathcal{D}_{\Z, \alpha q}$, the discrete Gaussian distribution centered around zero with standard deviation $\alpha q$. The parameter $\alpha \in (0, 1)$ is called the error rate. Let $n \ge 1$ and $q \ge 2$ be as above and let $r = r(n) < q$ be a positive integer. Let $\Sigma = \Z_r \times \Z_q^n$ and define the complex Euclidean space $\X = \C^\Sigma$. For a fixed $\bm{s} \in \Z_q^n$ define the probability distribution $\mu_{\bm{s}, r}: \SX \rightarrow [0, 1]$ as follows: choose $\bm{x} \in \Z_q^n$ uniformly at random and output the state
\[ \ket{\phi_{\bm{s}, r}(\bm{x})} = \frac{1}{\sqrt{r}} \sum_{j = 0}^{r - 1}\ket{j}\ket{\bm{x} + j\bm{s}}. \]
If we only have access to the output of $\mu_{\bm{s}, r}$, i.e., $\bm{x}$ is unknown, then the quantum system corresponding to the state $\ket{\phi_{\bm{s}, r}(\bm{x})}$ is described by the density operator
\[ \rho_{\bm{s}, r} = \frac{1}{q^n} \sum_{\bm{x} \in \Z_q^n} \ket{\phi_{\bm{s}, r}(\bm{x})} \bra{\phi_{\bm{s}, r}(\bm{x})} = \E_{\bm{x} \in \U(\Z_q^n)} \Big[ \ket{\phi_{\bm{s}, r}(\bm{x})} \bra{\phi_{\bm{s}, r}(\bm{x})} \Big], \]
Therefore, the output of the distribution $\mu_{\bm{s}, r}$ is always described by the density operator $\rho_{\bm{s}, r}$. In other words, the distribution $\mu_{\bm{s}, r}$ provides \textit{copies} of the state $\rho_{\bm{s}, r}$.
\begin{definition}[EDCP, Search]
    Let $n$, $q$ and $r$ be defined as above. The search-$\edcp_{n, q, r}$ is the problem of recovering $\bm{s}$ given samples from the distribution $\mu_{\bm{s}, r}$. A quantum algorithm $Q$ is said to solve $\edcp_{n, q, r}$ if it outputs $\bm{s}$ with probability at least $1 / \poly(n\log q)$ and has running time at most $\poly(n\log q)$.
\end{definition}
\begin{definition}[EDCP, Decision]
    \label{def:d-edcp}
    Let $n$, $q$ and $r$ be defined as above. Define the probability distribution $\gamma_r: \SX \rightarrow [0, 1]$ by choosing $(j, \bm{x}) \in \Z_r \times \Z_q^n$ uniformly at random and outputting the state $\ket{j}\ket{\bm{x}}$. The decision-$\edcp_{n, q, r}$ is the problem of distinguishing between the distributions $\mu_{\bm{s}, r}$ and $\gamma_r$.
\end{definition}
A quantum algorithm $Q$ is said to solve the decision-$\edcp_{n, q, r}$ if it succeeds with advantage at least $1 / \poly(n\log q)$ and has running time at most $\poly(n\log q)$. The density operator corresponding to the output of the distribution $\gamma_r$ in Definition \ref{def:d-edcp} is
\[ \rho = \frac{1}{rq^n} \sum_{j = 0}^{r - 1} \sum_{\bm{x} \in \Z_q^n}  \ket{j}\ket{\bm{x}} \bra{j}\bra{\bm{x}} = \E_{(j, \bm{x}) \in \U(\Z_r \times \Z_q^n)} \Big[ \ket{j}\ket{\bm{x}} \bra{j}\bra{\bm{x}} \Big] = \mathds{1}_{\X}, \]
Therefore, decision-$\edcp_{n, q, r}$ is the problem of distinguishing between the same number of copies of the states $\rho_{\bm{s}, r}$ and $\mathds{1}_{\X}$. For an integer $m > 0$, we denote by $\edcp_{n, q, r}^m$ the $\edcp$ problem in which the number of samples from $\mu_{\bm{s}, r}$ is bounded by $m$. The following theorem establishes a polynomial-time equivalence between $\lwe$ and $\edcp$.
\begin{theorem}
    \label{thm:lwe-edcp}
    Let $\chi$ be a discrete Gaussian distribution centered around zero with standard deviation $\alpha q$. There is a polynomial-time quantum reduction from $\lwe_{n, q, \chi}$ to $\edcp_{n, q, r}^m$ with $m = \poly(n\log q)$ and $r = \poly(n\log q) / \alpha$. Conversely, for the same parameter relationship up to $\poly(n\log q)$ factors, there is a polynomial-time quantum reduction from $\edcp$ to $\lwe$. 
\end{theorem}
Note that the equivalence in Theorem \ref{thm:lwe-edcp} holds only when the number of samples $m = \poly(n\log q)$. Giving such an equivalence for arbitrary $m$ is an open problem. See Section \ref{sec:hardness-poly}.


%% ///////////////////////////////////////////////////////



\section{A Search to Decision Reduction}

In this section, we give a search-to-decision reduction for $\edcp$. The reduction works for a large class of moduli $q$. The technique we use is inspired by the one in \cite{micciancio2012trapdoors} for a search-to-decision reduction for LWE. We need the following lemma, which shows the self-reducibility of $\edcp$.
\begin{lemma}
    \label{lem:self-rd}
    For any $r' \le r$, given access to the distribution $\mu_{\bm{s}, r}$, we can efficiently sample from the distribution $\mu_{\bm{s}, r'}$. In particular, there is an efficient reduction from $\edcp_{n, q, r}$ to $\edcp_{n, q, r'}$.
\end{lemma}
\begin{proof}
    To keep the reduction efficient, we treat the two cases $r' > r / 2$ and $r' \le r / 2$ separately. If $r' > r / 2$ then a simple indicator function can be used to to produce samples from $\mu_{\bm{s}, r'}$. More precisely, define the function $f: [0, r) \rightarrow \{ 0, 1 \}$ by
    \[ f(x) = 
    \begin{cases}
        1 & \text{if } x < r', \\
        0 & \text{otherwise}.
    \end{cases} \]
    Then applying the transformation $\ket{j}\ket{\bm{y}}\ket{0} \mapsto \ket{j}\ket{\bm{y}}\ket{f(j)}$, where $\bm{y} \in \Z_q^n$, to $\rho_{\bm{s}, r} \in \mu_{\bm{s}, r}$ and measuring the last register results in the state $\rho_{\bm{s}, r'}$ with probability at least $1 / 2$. If the measurement outcome is not $1$ then we repeat the above process.

    If $r' \le r / 2$ then we proceed as follows. Consider the measurement $M$ on the space $\X$ defined by the operators
    \[ M_a = \sum_{b = 0}^{\ell - 1} \ket{b}\bra{ar' + b} \otimes \mathds{1}, \]
    where $\ell = r'$ for $0 \le a < \lfloor r / r'  \rfloor$ and $\ell = r - r'$ for $a = \lfloor r / r'  \rfloor$. This measurement can be implemented efficiently \cite[\S A.8]{kaye2007introduction}. If we perform $M$ on a sample $\rho_{\bm{s}, r}$ from $\mu_{\bm{s}, r}$ the probability of observing the outcome $a$ is
    \begin{align*}
        \tr(M_a^*M_a \rho_{\bm{s}, r})
        & = \E_{\bm{x} \in \U(\Z_q^n)} \Big[ \tr(M_a \ket{\phi_{\bm{s}, r}(\bm{x})} \bra{\phi_{\bm{s}, r}(\bm{x})} M_a^*) \Big] \\
        & = \frac{1}{r} \sum_{b, c = 0}^{\ell - 1} \E_{\bm{x} \in \U(\Z_q^n)}\Big[ \tr(\ket{b}\ket{\bm{x} + (ar' + b)\bm{s}} \bra{c}\bra{\bm{x} + (ar' + c)\bm{s}}) \Big] \\
        & = \frac{1}{r} \sum_{b, c = 0}^{\ell - 1} \E_{\bm{x} \in \U(\Z_q^n)}\Big[ \tr(\ket{b}\bra{c} \otimes \ket{\bm{x} + (ar' + b)\bm{s}} \bra{\bm{x} + (ar' + c)\bm{s}}) \Big] \\
        & = \frac{\ell}{r},
    \end{align*}
    and the post-measurement state corresponding to this outcome is
    \begin{align*}
        \frac{M_a \rho_{\bm{s}, r} M_a^*}{(\ell / r)}
        & = \frac{1}{r} \sum_{b, c = 0}^{\ell - 1} \E_{\bm{x} \in \U(\Z_q^n)}\Big[ \ket{b}\ket{\bm{x} + (ar' + b)\bm{s}} \bra{c}\bra{\bm{x} + (ar' + c)\bm{s}} \Big] \\
        & = \frac{1}{r} \sum_{b, c = 0}^{\ell - 1} \E_{\bm{x} \in \U(\Z_q^n)}\Big[ \ket{b}\ket{\bm{x} + b\bm{s}} \bra{c}\bra{\bm{x} + c\bm{s}} \Big] \\
        & = \rho_{\bm{s}, \ell},
    \end{align*}
    So if the outcome is $a \in [0, \lfloor r / r'  \rfloor)$ we obtain the state $\rho_{\bm{s}, r'}$, which is what we are looking for. Therefore, the probability of obtaining the desired state after one measurement is
    \[ \lfloor r / r' \rfloor \frac{\ell}{r} = \lfloor r / r' \rfloor \frac{r'}{r} \ge \left( \frac{r}{r'} - 1 \right)\frac{r}{r'} = 1 - \frac{r'}{r} \ge \frac{1}{2}. \]
    If the measurement outcome is $a = \lfloor r / r' \rfloor$ then we repeat the above process.
\end{proof}
It follows from the proof of Lemma \ref{lem:self-rd} that obtaining a sample from $\mu_{\bm{s}, r'}$ requires (an expected) $2$ samples from $\mu_{\bm{s}, r'}$. This means $\edcp_{n, q, r}^m$ is reduced to $\edcp_{n, q, r'}^{\Theta(m)}$ regardless of the ratio between $r$ and $r'$.
\begin{theorem}
    Let $q = p_1^{e_1} \cdots p_\ell^{e_\ell}$ be the prime factorization of $q$ and assume that the primes $p_i$ are of size $\poly(n)$. Let $0 < r < q$ and let $k$ be the number of primes $p_i < r$. Then there is a polynomial-time quantum reduction from solving worst-case search-$\edcp_{n, q, r}$, with overwhelming probability, to solving average-case decision-$\edcp_{n, q, r'}$, with non-negligible probability, for any $r' \le r$ such that $(r')^k \le r$, and $r' \le p_i^{e_i}$ for all $i$. 
\end{theorem}
\begin{proof}
    Let $D$ be an oracle for solving decision-$\edcp_{n, q, r'}$. The idea of the proof is to use $D$ and samples from the distribution $\mu_{\bm{s}, r}$ to recover $\bm{s} \bmod p_i^{h_i}$, with large-enough $h_i$, for each $i$, and then assemble the results using the Chinese remainder theorem to recover $\bm{s} \bmod \prod_i p_i^{h_i}$. From there, since $q / \prod_i p_i^{h_i}$ is small-enough, we can use quantum Fourier transform to recover $\bm{s} \bmod q$. We shall compute $\bm{s} \bmod p_1^{e_1}$, the algorithm is the same for the other $p_i$. Let $p = p_1$ and $e = e_1$. The proof proceeds in several steps.

    \begin{enumerate}[leftmargin = *, font = \bfseries]
    \item Sampling from $\mu_{\bm{s}, r'}$: given samples from $\mu_{\bm{s}, r}$, according to Lemma \ref{lem:self-rd}, we can efficiently sample from $\mu_{\bm{s}, r'}$. So from now on we assume that we have access to samples from $\mu_{\bm{s}, r'}$.
    \item Building hybrid distributions: from the distribution $\mu_{\bm{s}, r'}$ we construct the distribution $\mu_{\bm{s}, r'}^k$ for all $k = 0, \dots, e$. Given a sample $\rho_{\bm{s}, r'} \in \mu_{\bm{s}, r'}$, a sample from $\mu_{\bm{s}, r'}^k$ is constructed by computing $j \bmod p^k$ into an auxiliary register and then discarding the register. More precisely, denote by $\ket{\phi_{\bm{s}, r'}^k(\bm{x})}$ the result of 
    \begin{align}
        \ket{\phi_{\bm{s}, r'}(\bm{x})}\ket{0}
        & \mapsto \frac{1}{\sqrt{r'}} \sum_{j = 0}^{r' - 1} \ket{j}\ket{\bm{x} + j\bm{s}}\ket{j \bmod p^k} \label{equ:r-1}  \\
        & \mapsto \frac{1}{\sqrt{r_k}} \sum_{j = 0}^{r_k - 1} \ket{jp^k + c}\ket{\bm{x} + (jp^k + c)\bm{s}}, \nonumber \tag{discard the last register}
    \end{align}
    where $0 < r_k \le \lfloor r' / p^k \rfloor$ and the random constant $0 \le c \le p^k - 1$ depend on the outcome of measuring the last register. Then
    \[ \rho_{\bm{s}, r'}^k = \E_{\bm{x} \in \U(\Z_q^n)} \Big[ \ket{\phi_{\bm{s}, r'}^k(\bm{x})} \bra{\phi_{\bm{s}, r'}^k(\bm{x})} \Big] \]
    is a sample from $\mu_{\bm{s}, r'}^k$.
    \item\label{step:s-mod-p} Computing $\bm{s} \bmod p$: for $k = 0$ we have $j = 0 \bmod p^0$ for all $j$, so $\rho_{\bm{s}, r'}^0 = \rho_{\bm{s}, r'}$ hence $\mu_{\bm{s}, r'}^0 = \mu_{\bm{s}, r'}$. Let $h$ be the smallest integer such that $r' \le p^h$, such an $h$ exists since $r' \le p^e$ by assumption. Then for $k = h$, discarding the last register in \eqref{equ:r-1} collapses the state $\rho_{\bm{s}, r'}$ to $\mathds{1}$. Therefore, by a hybrid argument, Lemma \ref{lem:hybrid}, there is a minimal $0 < t \le h$ such that $D$ can distinguish between $\mu_{\bm{s}, r'}^{t - 1}$ and $\mu_{\bm{s}, r'}^t$ with non-negligible advantage. Using the amplification technique of Section \ref{sec:err-red} we can assume that the distinguishing advantage of $D$ is exponentially close to $1$. Let $\bm{s} = (s_1, \dots, s_n)$. We recover $s_1 \bmod p$, the other $s_i \bmod p$ can be recovered similarly. Consider the state $\ket{\phi_{\bm{s}, r'}^{t - 1}(\bm{x})}$ where $\bm{x} = (x_1, \dots, x_n)$, and let $a \in \Z_p$ and $\bm{y} = (y_1, \dots, y_n) \in \Z_q^n$ be arbitrary. If we perform the transformation
    \begin{equation}
        \label{equ:s1-trans}
        U_1: \ket{j}\ket{\bm{y}}\ket{0} \mapsto \ket{j}\ket{\bm{y}}\ket{y_1 - ja \bmod p^t}
    \end{equation}
    on $\ket{\phi_{\bm{s}, r'}^{t - 1}(\bm{x})}$ we have
    \[ U_1\ket{\phi_{\bm{s}, r'}^{t - 1}(\bm{x})}\ket{0} = \frac{1}{\sqrt{r_{t - 1}}} \sum_{j = 0}^{r_{t - 1} - 1} \ket{jp^{t - 1} + c}\ket{\bm{x} + (jp^{t - 1} + c)\bm{s}}\ket{x_1 + (jp^{t - 1} + c)(s_1 - a) \bmod p^t}. \]
    If we measure the last register, the resulting state will be a sample from $\mu_{\bm{s}, r'}^{t - 1}$ or $\mu_{\bm{s}, r'}^t$ depending on whether $s_1 = a$ or $s_1 \ne a \bmod p$:
    \begin{itemize}
    \item $s_1 = a \bmod p$. In this case, the value of the last register is $x_1 + (s_1 - a)c \bmod p^t$. So the last register is not entangled with the first two registers, and we obtain the original sample from $\mu_{\bm{s}, r'}^{t - 1}$.
    \item $s_1 \ne a \bmod p$. Let $0 \le c_1 \le p^k - 1$ be the outcome of the measurement. Then the post-measurement state contains the terms with $j$ satisfying $jp^{t -1} = (c_1 - x_1) / (s_1 - a) - c \bmod p^t$. If we write the right hand side as $c_2p^{t - 1}$ for some constant $0 \le c_2 \le p - 1$ then $j = c_2 \bmod p$ and the post-measurement state is 
    \begin{align*}
        \ket{\psi_{\bm{x}}}
        & = \frac{1}{\sqrt{r_t}} \sum_{j = 0}^{r_t - 1} \ket{(jp + c_2)p^{t - 1} + c}\ket{\bm{x} + ((jp + c_2)p^{t - 1} + c)\bm{s}} \\
        & = \frac{1}{\sqrt{r_t}} \sum_{j = 0}^{r_t - 1} \ket{jp^t + c_2p^{t - 1} + c}\ket{\bm{x} + (jp^t + c_2p^{t - 1} + c)\bm{s}}
    \end{align*}
    where $0 < r_t \le \lfloor r_{t - 1} / p \rfloor$. We clearly have
    \[ \E_{\bm{x} \in \U(\Z_q^n)} \Big[ \ket{\psi_{\bm{x}}}\bra{\psi_{\bm{x}}}  \Big] \in \mu_{\bm{s}, r'}^t. \]
    \end{itemize}
    Therefore, using $D$ we can find out whether $s_1 = a \bmod p$. Since $p < \poly(n)$, we can recover $s_1 \bmod p$ by trying every $a \in \Z_p$.
    \item\label{step:s-mod-pk} Computing $\bm{s} \bmod p^k$: assume we have recovered, for some $k > 1$, the first $k - 1$ digits of $s_1$ in base $p$, that is we have computed $0 \le \tilde{s}_1 < p^{k - 1}$ such that $\tilde{s}_1 = s_1 \bmod p^{k - 1}$. Let $s_{1, k}$ be the $k$-th digit of $s_1$ in base $p$. To compute $s_{1, k}$, we can modify the transformation in Step \ref{step:s-mod-p} as
    \begin{equation*}
        U_k: \ket{j}\ket{\bm{y}}\ket{0} \mapsto \ket{j}\ket{\bm{y}}\ket{y_1 - j\tilde{s}_1 - jp^{k - 1}a \bmod p^{t + k - 1}}.
    \end{equation*}
    Applying $U_k$ to a sample from $\mu_{\bm{s}, r'}^{t - 1}$ and measuring the last register produces a sample from $\mu_{\bm{s}, r'}^{t - 1}$ or $\mu_{\bm{s}, r'}^t$ depending on whether $s_{1, k} = a$ or $s_{1, k} \ne a \bmod p$. This method works as long as $t + k - 1 \le e$.
    \item Quantum Fourier transform: using the procedure in Step \ref{step:s-mod-pk}, we can compute $\bm{s} \bmod p^{e - t + 1}$ where $t$ is  the minimal integer determined in Step \ref{step:s-mod-p}. Similarly, we recover $\bm{s} \bmod p^{e_i - t_i + 1}$ with $t_i$ the corresponding minimal integer for $p_i$, for all $i$. Note that if $r' \le p_i$ then $t_i = 1$. Also, we always have $r' \ge p_i^{t_i - 1}$. Using the Chinese remainder theorem we can compute $\tilde{\bm{s}} = \bm{s} \bmod v$ where
    \[ v = \prod_{i = 1}^\ell p_i^{e_i - t_i + 1} = q / \prod_{i = 1}^\ell p_i^{t_i - 1} \ge \frac{q}{(r')^k} \ge \frac{q}{r}. \]
    Now, by applying the transformation $\ket{j}\ket{\bm{y}} \mapsto \ket{j}\ket{\bm{y} - j\tilde{\bm{s}}}$ to the states $\ket{\phi_{\bm{s}, r}(\bm{x})}$, we assume that all the coordinates of $\bm{s}$ are multiples of $v$. Next, using Lemma \ref{lem:self-rd}, we project $\ket{\phi_{\bm{s}, r}(\bm{x})}$ onto $\ket{\phi_{\bm{s}, q'}(\bm{x})}$, where $q' = q / v \le r$. Finally, apply $\qft_{q^n}$ to the second register of $\ket{\phi_{\bm{s}, q'}(\bm{x})}$ and measure to obtain the state
    \[ \frac{1}{\sqrt{r}} \sum_{j = 0}^{q' - 1} \omega_q^{j\lrang{\bm{u}, \bm{s}}} \ket{j} = \frac{1}{\sqrt{r}} \sum_{j = 0}^{q' - 1} \omega_{q'}^{j\lrang{\bm{u}, \bm{s} / v}} \ket{j} = \qft_{q'}\ket{\lrang{\bm{u}, \bm{s} / v} \bmod q'}, \]
    where $\bm{u} \in \Z_q^n$ is uniformly random. Applying $\qft_{q'}^*$ to the above state, we obtain $\lrang{\bm{u}, \bm{s} / v} \bmod q'$. The value $\bm{s} / v$ can be computed, with high probability, by gathering $O(n)$ of these linear equations. \qedhere
    \end{enumerate}
\end{proof}
\begin{corollary}
    Let $q = p_1^{e_1} \cdots p_\ell^{e_\ell}$ be the prime factorization of $q$ and assume that the primes $p_i$ are of size $\poly(n)$. If $r \le p_i$ for all $1 \le i \le \ell$ then there is a polynomial-time quantum reduction from solving search-$\edcp_{n, q, r}$ to solving decision-$\edcp_{n, q, r}$. 
\end{corollary}
It follows from the above corollary that for a prime power $q = p^e$, where $p < \poly(n)$ and $r \le p$ then search-$\edcp_{n, q, r}$ and decision-$\edcp_{n, q, r}$ are quantum polynomial-time equivalent. Two interesting special cases of this equivalence are $q = 2^e, r = 2$ and $q = p, r < p$.



%% ///////////////////////////////////////////////////////



\section{A Better Decision Problem}
\label{sec:new-decsn}

In this section, we propose an $\edcp$ decision problem that will be more suitable for applications than the one defined in Section \ref{sec:preli}. We assume, as before, that the modulus $q$ has $\poly(n)$-bounded prime factors. Perhaps the new decision problem is best understood for a prime modulus $q$. So let us assume, for now, that $q$ is a $\poly(n)$-bounded prime. 

Define the distribution $\tilde{\mu}_{\bm{s}, r}$ on the unit sphere $\SX$ by choosing $\bm{x} \in \Z_q^n$ and $t \in \Z_q {\setminus} \{ 0 \}$ uniformly at random and outputting the state
\begin{equation}
    \label{equ:new-dec}
    \ket{\tilde{\phi}_{\bm{s}, r}(\bm{x})} = \frac{1}{\sqrt{r}} \sum_{j = 0}^{r - 1} \omega_q^{jt} \ket{j}\ket{\bm{x} + j\bm{s}}.
\end{equation}
The new decision problem is to distinguish between the distributions $\mu_{\bm{s}, r}$ and $\tilde{\mu}_{\bm{s}, r}$. The motivation behind this new definition is that the state \eqref{equ:new-dec} can be efficiently transformed into a \textit{shifted} LWE sample $(\bm{a}, \lrang{\bm{a}, \bm{s}} + e + t)$ where $e$ is sampled from $\mathcal{D}_{\Z, q / r}$. For a large enough $q$, this pair is closer to a uniformly random element of $\Z_q^n \times \Z_q$ than an LWE sample. An instance of the above decision problem then translates to an instance of the LWE decision problem. The transformation of \eqref{equ:new-dec} into a shifted LWE sample can be done using the technique in \cite{brakerski2018learning}: given the state $\ket{\tilde{\phi}_{\bm{s}, r}(\bm{x})}$, we first apply the transformation $\ket{j} \mapsto \ket{j - \lfloor (r - 1) / 2 \rfloor}$ to the first register to obtain the state
\begin{equation}
    \label{equ:symm-edcp}
    \frac{1}{\sqrt{r}} \sum_{j = -\lfloor (r - 1) / 2 \rfloor}^{\lceil (r - 1) / 2 \rceil} \omega_q^{jt} \ket{j}\ket{\bm{x} + j\bm{s}},
\end{equation}
where we have again denoted the uniformly random element $\bm{x} + \lfloor (r - 1) / 2 \rfloor \bm{s} \in \Z_q^n$ by $\bm{x}$. Next, using the quantum rejection sampling we can, with probability $\Omega(\sigma / r) = \Omega(1 / \sqrt{\kappa})$, transform \eqref{equ:symm-edcp} into 
\begin{equation}
    \label{equ:symm-eg}
    \sum_{j = -\lfloor (r - 1) / 2 \rfloor}^{\lceil (r - 1) / 2 \rceil} \omega_q^{jt} g_\sigma(j) \ket{j}\ket{\bm{x} + j\bm{s}},
\end{equation}
where $g_\sigma(x) = \exp(-\pi x^2 / \sigma^2)$ is the Gaussian distribution. Now if we apply the transform $\qft_q \otimes \qft_{q^n}$ to \eqref{equ:symm-eg} and measure the last register we obtain the state
\[ \ket{\psi} =  \frac{1}{\sqrt{q}} \sum_{y \in \Z_q} \sum_{j = -\lfloor (r - 1) / 2 \rfloor}^{\lceil (r - 1) / 2 \rceil} \omega_q^{j(\lrang{\bm{a}, \bm{s}} + y + t)} g_\sigma(j) \ket{y},\]
where $\bm{a} \in \Z_q^n$ is uniformly random and known. We have
\begin{align*}
    \ket{\psi}
    & \approx_\epsilon \sum_{y \in \Z_q} \sum_{j \in \Z} \omega_q^{j(\lrang{\bm{a}, \bm{s}} + y + t)} g_\sigma(j) \ket{y} \tag{by Lemma ??} \\
    & = \sum_{y \in \Z_q} \sum_{j \in \Z} g_{1/\sigma} \Big( j + \frac{\lrang{\bm{a}, \bm{s}} + y + t}{q} \Big) \ket{y} \tag{by Lemma ??} \\
    & = \sum_{e \in \Z} g_{1/\sigma} \Big( \frac{e}{q} \Big) \ket{\lrang{-\bm{a}, \bm{s}} + e - t \bmod q} \tag{$e = jq + \lrang{\bm{a}, \bm{s}} + t + y$} \\
    & \approx_\epsilon \sum_{e \in \Z_q} g_{1/\sigma} \Big( \frac{e}{q} \Big) \ket{\lrang{-\bm{a}, \bm{s}} + e - t} \tag{by Lemma ??}.
\end{align*}
Measuring the above state, we obtain a pair $(-\bm{a}, \lrang{-\bm{a}, \bm{s}} + e - t)$ where $e$ is sampled from $\mathcal{D}_{\Z, q / \sigma}$. For a general modulus $q$, an immediate generalization of the decision problem would be to just replace the prime modulus with a general one, and the above transformation to an LWE sample goes through without any change. However, for such a generalization, it is not clear how to reduce the search problem to the decision problem when $q$ is super-polynomially large in $n$.
\begin{definition}[EDCP, Decision]
    Let $p \mid q$ be a prime. Define the distribution $B_{\bm{s}, r, p}$ on the unit sphere $\SX$ by choosing $\bm{x} \in \Z_q^n$ and $t \in \Z_p {\setminus} \{ 0 \}$ uniformly at random and outputting the state
    \begin{equation}
        \ket{
            \phi_{\bm{s}, r, p}(\bm{x})} = \frac{1}{\sqrt{r}} \sum_{j = 0}^{r - 1} \omega_p^{jt} \ket{j}\ket{\bm{x} + j\bm{s}}.
    \end{equation}
    The decision-$\edcp_{n, q, r}$ is the problem of distinguishing between the distribution $B_{\bm{s}, r}$ and any distribution in the set $\{ B_{\bm{s}, r, p} \}_{p \mid q}$.
\end{definition}
\begin{theorem}
    Assume that all the prime factors of $q$ are $\poly(n)$-bounded. Then there is a polynomial-time quantum reduction from solving search-$\edcp_{n, q, r}$ to solving decision-$\edcp_{n, q, r}$.
\end{theorem}
\begin{proof}
    Let $q = p_1^{e_1} \cdots p_\ell^{e_\ell}$ be the prime factorization of $q$. Let $D$ be an oracle for solving decision-$\edcp_{n, q, r}$. The idea is to use $D$ to find $\bm{s} \bmod p_i^{e_i}$ for all $i$ and then reconstruct $\bm{s} \bmod q$ using the Chinese remainder theorem. Let $\bm{s} = (s_1, \dots, s_n)$. We show how to recover $s_1 \bmod p_1^{e_1}$, the other values $s_i \bmod p_j^{e_j}$ can be computed similarly. Set $p = p_1$ and $e = e_1$.
    For any $y \in \Z_p$ and nonzero $c \in \Z_p$ define the following unitary on $\X$
    \[ U_{c, y} \ket{j}\ket{\bm{a}} = \omega_p^{(a_1 - jy)c}\ket{j}\ket{\bm{a}}, \]
    where $a_1$ is the first coordinate of $\bm{a}$. Given a sample $\rho_{\bm{s}, r}$ from $B_{\bm{s}, r}$, fix $y \in \Z_p$ and select a fresh nonzero $c \in \Z_p$ uniformly at random. Then we have
    \[ U_{c, y}\ket{\phi_{\bm{s}, r}(\bm{x})} = \frac{1}{\sqrt{r}} \omega_p^{x_1}\sum_{j = 0}^{r - 1} \omega_p^{j(s_1 - y)c} \ket{j}\ket{\bm{x} + j\bm{s}}. \]
    Therefore, ignoring the global phase, if $s_1 \ne y \bmod p$ then $U_{c, y} \rho_{\bm{s}, r} U_{c, y}^*$ is a sample from $B_{\bm{s}, r, p}$, otherwise $U_{c, y} \rho_{\bm{s}, r} U_{c, y}^* = \rho_{\bm{s}, r}$. So, the oracle $D$ could tell us which is the case. Trying all $y \in \Z_p$ we can find $s_1 \bmod p$. Now assume we have recovered $\tilde{s}_1 = s_1 \bmod p^k$ for $k < e$. To compute $s_1 \bmod p^{k + 1}$, we can modify the unitary $U_{c, y}$ as 
    \[ U_{c, y, k} \ket{j}\ket{\bm{a}} = \omega_{p^{k + 1}}^{(a_1 - j\tilde{s}_1 - jp^ky)c}\ket{j}\ket{\bm{a}}. \]
    To see how $U_{c, y, k}$ acts on a sample $\rho_{\bm{s}, r}$ from $B_{\bm{s}, r}$, let $s_{1, k + 1}$ be the $(k + 1)$-th digit of $s_1$ in base $p$. Then
    \begin{align*}
        U_{c, y, k} \ket{j}\ket{\bm{x} + j\bm{s}}
        & = \omega_{p^{k + 1}}^{(x_1 + js_1 - j\tilde{s}_1 - jp^ky)c}\ket{j}\ket{\bm{x} + j\bm{s}} \\
        & = \omega_{p^{k + 1}}^{x_1} \omega_p^{j(s_{1, k + 1} - y)c}\ket{j}\ket{\bm{x} + j\bm{s}}.
    \end{align*}
    Therefore, repeating the above procedure, we can recover $s_{1, k + 1}$. This completes the proof.
\end{proof}



%% ///////////////////////////////////////////////////////



\section{Quantum Public-Key Cryptosystem}
\label{sec:public-key-enc}

A quantum public-key cryptosystem is, similar to a classical system, a set of three algorithms:
\begin{itemize}[itemsep = 1pt]
\item $\gen(1^n)$ generates a public-key $pk$ and a secret-key $sk$, based on the security parameter $n$.
\item $\enc(pk, m)$, outputs a ciphertext $c$ for a given public-key $pk$ and message $m$.
\item $\dec(sk, c)$, outputs a message $m$ for a given secret-key $sk$ and ciphertext $c$.
\end{itemize}
The output pair $(pk, sk)$ of the $\gen$ algorithm for a quantum system is a consists usually of a quantum state and a classical state, respectively. In particular, the public-key $pk$ is a quantum state that is generated using a classical key $sk$. The algorithm $\enc$ encrypts the message $m$, which is classical information, using the quantum state $pk$. The output $c$ of $\enc$ is a quantum state. The algorithm $\dec$ uses the key $sk$ to decrypt the quantum state into a classical message $m$.

For the security parameter $n$, we set the parameters for public key system as follows. We choose $q = \poly(n)$ such that $q = 2^s$ for some integer $s > 0$. We also set $r = 2^{s'}$ where $s' < s$. The main reason for these choices of parameters is efficiency, as we shall explain at the end of this section. In what follows we describe our cryptosystem for encrypting a one-bit message $b \in \{ 0, 1 \}$.

\vspace*{\topskip}

$\gen(1^n)$: Select $\bm{x}, \bm{s} \in \Z_q^n$ uniformly at random. Apply the transformation $\qft_r \otimes \mathds{1}$ to the register $\ket{0} \ket{\bm{x}}$ to obtain the state $\ket{\psi_1} = \frac{1}{\sqrt{r}} \sum_{j = 0}^{r - 1} \ket{j} \ket{\bm{x}}$. Apply the transformation $\ket{j}\ket{\bm{x}} \mapsto \ket{j}\ket{\bm{x} + j\bm{s}}$ to $\ket{\psi_1}$ to obtain the state
\[ \ket{\phi_{\bm{s}, r, 0}(\bm{x})} = \frac{1}{\sqrt{r}} \sum_{j = 0}^{r - 1} \ket{j} \ket{\bm{x} + j\bm{s}}. \]
Return the public-key, secret-key pair $(pk, sk) = (\ket{\phi_{\bm{s}, r, 0}(\bm{x})}, \bm{s})$.     

\begin{figure}
    \centering
    \begin{quantikz}[thin lines]
        \lstick{$\ket{0}$} & \gate{\qft_r} & \ctrl{1} & \qw \\
        \lstick{$\ket{\bm{x}}$} & \qw  & \gate{A} & \qw 
    \end{quantikz}
    \caption{The key generation circuit. The gate $\qft_r$ is the quantum fourier transform over $\Z_r$, and the gate $A$ is the multiply-add operation $\ket{j}\ket{\bm{x}} \mapsto \ket{j}\ket{\bm{x} + j\bm{s}}$.}
\end{figure}

\vspace*{\topskip}

$\enc(pk = \rho_{\bm{s}, r, 0}, b \in \{ 0, 1 \})$:  Apply the transformation $U: \ket{j}\ket{\bm{y}} \mapsto (-1)^{bj}\ket{j}\ket{\bm{y}}$ to $\rho_{\bm{s}, r, 0}$ to obtain the state
\begin{align*}
    U \rho_{\bm{s}, r, 0} U^*
    & = U \E_{\bm{x} \leftarrow \Z_q^n} \Big[ \ket{\phi_{\bm{s}, r, 0}(\bm{x})} \bra{\phi_{\bm{s}, r, 0}(\bm{x})} \Big] U^* \\
    & = \E_{\bm{x} \leftarrow \Z_q^n} \Big[ U \ket{\phi_{\bm{s}, r, 0}(\bm{x})} \bra{\phi_{\bm{s}, r, 0}(\bm{x})} U^* \Big] \\
    & = \E_{\bm{x} \leftarrow \Z_q^n} \Big[ \ket{\phi_{\bm{s}, r, b}(\bm{x})} \bra{\phi_{\bm{s}, r, b}(\bm{x})} \Big] \\
    & = \rho_{\bm{s}, r, b}.
\end{align*}
Return $\rho_{\bm{s}, r, b}$.

\begin{figure}
    \centering
    \begin{quantikz}[thin lines]
         \lstick{$\ket{j}$} & \qw & \qw & \ctrl{2} & \qw & \qw \\
          \lstick{$\ket{\bm{y}}$} & \qw & \qw & \qw & \qw & \qw \\
        \lstick{$\ket{0}$} & \gate{X} & \gate{H} & \gate{U_b} & \meter{} & \qw
    \end{quantikz}
    \caption{The encryption circuit. The gate $U_b$ performs the operation $\ket{j}\ket{c} \mapsto \ket{j}\ket{c \oplus (jb \bmod 2)}$.}
\end{figure}

\vspace*{\topskip}

$\dec(sk = \bm{s}, c = \rho_{\bm{s}, r, b})$:  Apply the transformation $S: \ket{j}\ket{\bm{y}} \mapsto \ket{j}\ket{\bm{y} - j\bm{s}}$ to $\rho_{\bm{s}, r, b}$. Discard the second register. Apply $\qft_r$ to the resulting state and measure. If the measurement result is 0 then output 0, otherwise output 1.

\begin{figure}
    \centering
    \begin{quantikz}[thin lines]
        \lstick{$\ket{j}$} & \ctrl{1} & \gate{\qft_r} & \meter{} & \qw \\
        \lstick{$\ket{\bm{y}}$} & \gate{S} & \meter{} & \qw & \qw
    \end{quantikz}
    \caption{The decryption circuit. The gate $\qft_r$ is the quantum fourier transform over $\Z_r$, and the gate $S$ is the multiply-subtract operation $\ket{j}\ket{\bm{x}} \mapsto \ket{j}\ket{\bm{x} - j\bm{s}}$.}
\end{figure}

\begin{lemma}[Correctness]
    For any bit $b \in \{ 0, 1 \}$ and all outputs $(\bm{s}, \rho_{\bm{s}, r, 0})$ of $\gen$, we have
    \[ \Pr [ \dec(\bm{s}, \enc(\rho_{\bm{s}, r, 0}, b)) = b ] = 1. \]
\end{lemma}
\begin{proof}
    Given a ciphertext $\rho_{\bm{s}, r, b}$, the decryption steps are as follows
    \begin{align*}
        \rho_{\bm{s}, r, b}
        & \mapsto \E_{\bm{x} \leftarrow \Z_q^n} \Big[ A \ket{\phi_{\bm{s}, r, b}(\bm{x})} \bra{\phi_{\bm{s}, r, b}(\bm{x})} A^* \Big]  \tag{apply $A$} \\
        & = \E_{\bm{x} \leftarrow \Z_q^n} \bigg[ \frac{1}{r} \sum_{k, j = 0}^{r - 1} (-1)^{b(j - k)}\ket{k}\ket{\bm{x}} \bra{j}\bra{\bm{x}} \bigg] \\
        & = \frac{1}{r} \sum_{k, j = 0}^{r - 1} (-1)^{b(j - k)}\ket{k}\bra{j} \otimes \E_{\bm{x} \leftarrow \Z_q^n} \Big[ \ket{\bm{x}}\bra{\bm{x}} \Big] \\
        & \mapsto \frac{1}{r} \sum_{k, j = 0}^{r - 1} (-1)^{b(j - k)}\ket{k}\bra{j} \tag{discard the second register} \\
        & \mapsto \qft_r \frac{1}{r} \sum_{k, j = 0}^{r - 1} (-1)^{b(j - k)}\ket{k}\bra{j} \qft_r^* \tag{apply quantum Fourier transform}\\
        & = \ket{br/2} \bra{br/2}
    \end{align*}
    If $b = 0$ then the state of the system is $\ket{0} \bra{0}$, otherwise it is $\ket{r / 2} \bra{r / 2}$. 
\end{proof}



%% ///////////////////////////////////////////////////////




\section{Information-Theoretic and Hardness Bounds}
\label{sec:hardness}

In this section, we derive hardness bounds for $\edcp$ based on the number of samples. The $\edcp_{n, q, r}^m$ problem is to recover the secret $\bm{s} \in \Z_q^n$ given $m$ copies of the state $\rho_{\bm{s}, r}$. We consider bounds $O( n\log q / \log r)$, $\poly(n)$ and $2^{O(\sqrt{n \log q})}$ for $m$. As $m$ increases, $\edcp$ becomes easier. Figure \ref{fig:hardness-bounds} summarizes the hardness of $\edcp$ based on these bounds.  

\begin{figure}
    \centering
    \begin{tikzpicture}[tick/.style = {draw = black, fill = red, inner sep = 0.4mm}]
        \draw [thick, -{latex}] (0, 0) -- (0, 3) node[above] {\scriptsize \# samples};
        \node [tick] (t1) at (0, 1) {};
        \node [tick] (t2) at (0, 2) {};

        \node [below left = 1mm of t1] {$\displaystyle O\Big( n \frac{\log q}{\log r} \Big)$};
        \node [below right = 1mm of t1] {Information-theoretically secure};
        \node [below left = 1mm of t2] {$\poly(n)$};
        \node [below right = 1mm of t2] {as hard as $\lwe$};
        \node [above left = 1mm of t2] {$\displaystyle 2^{O(\sqrt{n \log q})}$};
        \node [above right = 1mm of t2] {can be solved in $\displaystyle 2^{O(\sqrt{n \log q})}$};
    \end{tikzpicture}
    \caption{The hardness of $\edcp$ based on the number of samples. These bounds also hold for the security of the public-key encryption scheme of Section \ref{sec:public-key-enc}. In that case, a sample is a copy of the public key.}
    \label{fig:hardness-bounds}
\end{figure}





\subsection{Limited number of samples}
\label{sec:hardness-limited}

We derive a lower bound on $m$ using tools from quantum information theory. A special case of the result of this section was also obtained in \cite{bacon2005optimal}. To better understand the problem we can model it in the following standard way, for $m = 1$. Alice selects a uniformly random $\bm{s} \in \Z_q^n$ and stores it in the classical register $\mathsf{Y}$. She then prepares a register $\mathsf{X}$ in the state $\rho_{\bm{s}, r}$ and sends $\mathsf{X}$ to Bob. So, Bob has access to the register $\mathsf{X}$ that is prepared according to the ensemble
\[
\begin{array}{rrll}
    \eta: & \Z_q^n & \longrightarrow & \mathrm{Pos}(\X) \\
    & \bm{s} & \longmapsto & \frac{1}{q^n}\rho_{\bm{s}, r},
\end{array}
\]
where $\mathrm{Pos(\X)}$ is the space of positive semidefinite operators on $\X$. Bob picks a measurement $\mu: \Z_q^n \rightarrow \mathrm{Pos}(\X)$ and measures $\mathsf{X}$ according to $\mu$. He stores the outcome of the measurement in a classical register $\mathsf{Z}$. The pair $(\mathsf{Y}, \mathsf{Z})$ of classical registers will be distributed according to the distribution
\[
\begin{array}{rrll}
    q: & \Z_q^n \times \Z_q^n & \longrightarrow & [0, 1] \\
    & (\bm{s}, \bm{u}) & \longmapsto & \lrang{\mu(\bm{u}), \eta(\bm{s})}.
\end{array}
\]
The amount of information that Bob can learn about $\mathsf{Y}$ using the measurement $\mu$ is determined by the mutual information between $\mathsf{Y}$ and $\mathsf{Z}$, which we denote by $\operatorname{I}_\mu(\eta)$. The accessible information of the ensemble $\eta$ is defined as
\[ \operatorname{I}(\eta) = \sup_{\mu} \operatorname{I}_\mu(\eta), \]
where the supremum ranges over all choices of the measurement $\mu$. Note that the pair $(\mathsf{Y}, \mathsf{X})$ is in the classical-quantum state
\[ \sigma = \sum_{\bm{s} \in \Z_q^n} \ket{\bm{s}}\bra{\bm{s}} \otimes \eta(\bm{s}). \]
The quantum mutual information between $\mathsf{Y}$ and $\mathsf{X}$, with respect to the state $\sigma$, is called the Holevo information of the ensemble $\eta$ and is denoted by $\chi(\eta)$. We have
\begin{equation}
    \label{equ:holevo-chi}
    \chi(\eta) = \operatorname{I}(\mathsf{Y} : \mathsf{X}) = \entpy\Bigg( \frac{1}{q^n} \sum_{\bm{s} \in \Z_q^n} \rho_{\bm{s}, r} \Bigg) - \frac{1}{q^n} \sum_{\bm{s} \in \Z_q^n} \entpy(\rho_{\bm{s}, r}),
\end{equation}
where $\entpy(\cdot)$ is the von Neumann entropy.
\begin{theorem}[Holevo's theorem]
    \label{thm:holevo}
    Let $\Sigma$ be an alphabet and let $\X$ be a complex Euclidean space. For any ensemble $\eta: \Sigma \rightarrow \mathrm{Pos}(\X)$ it holds that $\operatorname{I}(\eta) \le \chi(\eta)$.
\end{theorem}
Therefore, according to Theorem \ref{thm:holevo}, we can obtain an upper bound on the accessible information of the ensemble $\eta$ by computing $\chi(\eta)$. For an arbitrary number of samples $m$, we need to bound $\chi(\eta^{\otimes m})$ for the ensemble
\begin{equation}
    \label{equ:ensem-m}
    \begin{array}{rrll}
        \eta^{\otimes m}: & \Z_q^n & \longrightarrow & \mathrm{Pos}(\X^{\otimes m}) \\
        & \bm{s} & \longmapsto & \frac{1}{q^n}\rho_{\bm{s}, r}^{\otimes m}.
    \end{array}
\end{equation}
This is done is the following theorem.
\begin{theorem}
    \label{thm:acc-bound}
    For the ensemble $\eta^{\otimes m}$ in \eqref{equ:ensem-m} we have $\chi(\eta^{\otimes m}) \le m(1 - q^{-n})\log r$.
\end{theorem}
\begin{proof}
    First, note that the entropy is additive with respect to tensor products, i.e., for any two states $\sigma_1$ and $\sigma_2$ it holds that $\entpy(\sigma_1 \otimes \sigma_2) = \entpy(\sigma_1) + \entpy(\sigma_2)$. It follows that $\entpy(\rho_{\bm{s}, r}^{\otimes m}) = m\entpy(\rho_{\bm{s}, r})$. Next, for a state $\sigma$ of a compound register $(\mathsf{X}_1, \cdots, \mathsf{X}_m)$, we have, by the subadditivity of von Neumann entropy,
    \[ \entpy(\sigma) \le \entpy(\tr_1(\sigma)) + \cdots + \entpy(\tr_m(\sigma))\]
    where $\tr_k(\sigma)$ is the reduction of $\sigma$ to the (state of the) register $\mathsf{X}_k$. Therefore,
    \begin{align*}
        \entpy\bigg( \frac{1}{q^n} \sum_{\bm{s} \in \Z_q^n} \rho_{\bm{s}, r}^{\otimes m} \bigg)
        & \le \sum_{i = 1}^m \entpy\bigg(\tr_i\bigg( \frac{1}{q^n} \sum_{\bm{s} \in \Z_q^n} \rho_{\bm{s}, r}^{\otimes m} \bigg)\bigg) \tag{by subadditivity of $\entpy$} \\
        & = \sum_{i = 1}^m \entpy\bigg(\frac{1}{q^n} \sum_{\bm{s} \in \Z_q^n} \tr_i(\rho_{\bm{s}, r}^{\otimes m}) \bigg) \tag{by linearity of $\tr$} \\
        & = m\entpy\bigg( \frac{1}{q^n} \sum_{\bm{s} \in \Z_q^n} \rho_{\bm{s}, r} \bigg).
    \end{align*}
    It follows from \eqref{equ:holevo-chi}  that $\chi(\eta^{\otimes m}) \le m\chi(\eta)$. Now, we can compute $\chi(\eta)$ by computing the eigenvalues of the operators $\rho_{\bm{s}, r}$ and $\rho = q^{-n}\sum_{\bm{s} \in \Z_q^n} \rho_{\bm{s}, r}$. The eigenvectors of $\rho_{\bm{s}, r}$ are
    \[ \ket{\psi_{\bm{x}, t}} = \frac{1}{\sqrt{r}} \sum_{j = 0}^{r - 1} \omega_r^{jt} \ket{j}\ket{\bm{x} + j\bm{s}}, \hspace*{2mm} (t, \bm{x}) \in \Z_r \times \Z_q^n, \]
    and the eigenvalues are $0$ and $q^{-n}$ with multiplicities $(r - 1)q^n$ and $q^n$, respectively. To compute the eigenvalues of $\rho$ it is best to write the second register in the Fourier basis. We have
    \begin{align*}
        (\mathds{1} \otimes \qft_{q^n}) \rho_{\bm{s}, r} (\mathds{1} \otimes \qft_{q^n})^*
        & = \E_{\bm{x} \in \U(\Z_q^n)} \Big[ (\mathds{1} \otimes \qft_{q^n}) \ket{\phi_{\bm{s}, r}(\bm{x})} \bra{\phi_{\bm{s}, r}(\bm{x})} (\mathds{1} \otimes \qft_{q^n})^* \Big] \\
        & = \frac{1}{rq^n} \sum_{\bm{y}, \bm{z} \in \Z_q^n} \E_{\bm{x} \in \U(\Z_q^n)} \Big[ \omega_q^{\lrang{\bm{x}, \bm{y} - \bm{z}}} \Big] \sum_{j, k \in \Z_r} \omega_q^{\lrang{j\bm{y} - k\bm{z}, \bm{s}}} \ket{j}\bra{k} \otimes \ket{\bm{y}}\bra{\bm{z}} \\
        & = \frac{1}{r} \E_{\bm{y} \in \U(\Z_q^n)} \Big[ \sum_{j, k \in \Z_r} \omega_q^{\lrang{(j - k)\bm{y}, \bm{s}}} \ket{j}\bra{k} \otimes \ket{\bm{y}}\bra{\bm{y}} \Big],
    \end{align*}
    where the last equality follows from the fact that
    \[
    \E_{\bm{x} \in \U(\Z_q^n)} \Big[ \omega_q^{\lrang{\bm{x}, \bm{y} - \bm{z}}} \Big] =
    \begin{cases}
        1 & \text{if } \bm{y} = \bm{z} \\
        0 & \text{if } \bm{y} \ne \bm{z}.
    \end{cases}
    \]
    Therefore, we have 
    \begin{align}
        (\mathds{1} \otimes \qft_{q^n}) \rho (\mathds{1} \otimes \qft_{q^n})^*
        & = \frac{1}{r} \E_{\bm{y} \in \U(\Z_q^n)} \Big[ \sum_{j, k \in \Z_r} \E_{\bm{s} \in \U(\Z_q^n)} \Big[ \omega_q^{\lrang{(j - k)\bm{y}, \bm{s}}} \Big] \ket{j}\bra{k} \otimes \ket{\bm{y}}\bra{\bm{y}} \Big] \nonumber \\
        & = \frac{1}{rq^n} \sum_{j, k \in \Z_r} \ket{j}\bra{k} \otimes \ket{0}\bra{0} + \frac{1}{rq^n} \mathds{1} \otimes (\mathds{1} - \ket{0}\bra{0}) \label{equ:f-basis}
    \end{align}
    where the second equality follows from
    \[
    \E_{\bm{s} \in \U(\Z_q^n)} \Big[ \omega_q^{\lrang{(j - k)\bm{y}, \bm{s}}} \Big] = 
    \begin{cases}
        1 & \text{if } (j - k)\bm{y} = 0 \\
        0 & \text{if } (j - k)\bm{y} \ne 0.
    \end{cases}
    \]
    The eigenvectors of \eqref{equ:f-basis} are
    \begin{align*}
        & \ket{\psi_{\bm{x}, t}} = \frac{1}{\sqrt{r}} \sum_{j = 0}^{r - 1} \omega_r^{jt} \ket{j}\ket{\bm{x}}, \hspace*{2mm} (t, \bm{x}) \in \Z_r \times \Z_q^n, \hspace*{1mm} \bm{x} \ne 0, \\
        & \ket{\psi_t} = \frac{1}{\sqrt{r}} \sum_{j = 0}^{r - 1} \omega_r^{jt} \ket{j}\ket{0}, \hspace*{2mm} t \in \Z_r,
    \end{align*}
    and the eigenvalues are $0$, $q^{-n}$ and $r^{-1}q^{-n}$ with multiplicities $r - 1$, $1$ and $(q^n - 1)r$, respectively. Finally, using \eqref{equ:holevo-chi} and the eigenvalues for $\rho$ and $\rho_{\bm{s}, r}$, we have
    \[ m\chi(\eta) \le m\Big( \frac{1}{q^n}\log(q^n) + \frac{r(q^n - 1)}{rq^n}\log(rq^n) - \log(q^n) \Big) = m\Big( 1 - \frac{1}{q^n} \Big)\log r. \qedhere \]
\end{proof}
Assume that Bob has found a measurement $\mu$ on $\eta^{\otimes m}$, i.e., a measurement that can operate on the joint state of $m$ copies of Alice's state, such that, after possibly some post-measurement processing, he can guess the value of $\mathsf{Y}$ with a constant probability $p$. Then a lower bound on $m$, that depends on $p$, can be computed using Theorem \ref{thm:acc-bound}. We need the following result known as Fano's inequality.
\begin{lemma}[Fanos inequality]
    \label{lem:fano-ineq}
    Let $X$ and $Y$ be random variables on some finite set $\Gamma$, and let $\tilde{X} = f(Y)$ for some function $f$. Let $p = \Pr[X \ne \tilde{X}]$. Then it holds that
    \[ \entpy(X \vert Y) \le p\log(\abs{\Gamma} - 1) + \entpy(p, 1 - p). \]
\end{lemma}
\begin{corollary}
    \label{cor:lower-b}
    Let $\bm{s} \in \Z_q^n$ be chosen uniformly at random. The number of copies of the state $\rho_{\bm{s}, r}$ needed to recover $\bm{s}$ with constant probability is at least $O(n\log q / \log r)$.
\end{corollary}
\begin{proof}
    Recall the communication scenario above: Alice selects $\bm{s} \in \Z_q^n$ uniformly at random and stores it in the register $\mathsf{Y}$. She then generates $m$ copies of the state $\rho_{\bm{s}, r}$ and sends them to Bob. On receiving $\rho_{\bm{s}, r}^{\otimes m}$, Bob applies a measurement $\mu$ and stores the measurement outcome in the register $\mathsf{Z}$. Bob might perform some post-processing on $\mathsf{Z}$ to obtain another register $\tilde{\mathsf{Z}}$. Assume that $p = \Pr[\mathsf{Y} \ne \tilde{\mathsf{Z}}]$ is a constant. Then
    \begin{align*}
        \operatorname{I}_\mu(\eta^{\otimes m})
        & = \operatorname{I}(\mathsf{X} : \mathsf{Z}) \\
        & = \entpy(\mathsf{Y}) - \entpy(\mathsf{Y} \vert \mathsf{Z}) \tag{by definition} \\
        & \ge n\log(q) - (1 - p)\log(q^n - 1) - \entpy(p, 1 - p) \tag{by Lemma \ref{lem:fano-ineq}} \\
        & \ge pn\log(q) - 1
    \end{align*}
    Now, by Theorem \ref{thm:acc-bound}, $m(1 - q^{-n})\log r \ge \chi(\eta^{\otimes m}) \ge \operatorname{I}_\mu(\eta^{\otimes m})$ which completes the proof.
\end{proof}
\begin{remark}
    An interesting case for which the bound in Corollary \ref{cor:lower-b} is tight is when $q = r$. In this case, given the state $\rho_{\bm{s}, r}$, applying the transform $\qft_r^* \otimes \qft_{q^n}$ results in the state
    \[ \frac{1}{\sqrt{q^n}} \sum_{\bm{y} \in \Z_q^n} \omega_q^{\lrang{\bm{y}, \bm{x}}} \ket{\lrang{\bm{y}, \bm{s}}}\ket{\bm{y}}. \]
    Measuring this state we obtain a linear equation $\lrang{\bm{y}, \bm{s}}$, where $\bm{y} \in \Z_q^n$ is uniformly random. We can solve for $\bm{s}$ by gathering $O(n)$ of these linear equations. 
\end{remark}



\subsection{Polynomial number of samples}
\label{sec:hardness-poly}

When the number of samples is $\poly(n)$, $\edcp$ is quantum polynomially equivalent to $\lwe$ \cite{brakerski2018learning}. The reduction form $\edcp$ to $\lwe$ is proved as in Section \ref{sec:new-decsn}. The reduction from $\lwe$ to $\edcp$ is based on the ball-intersection technique that was originally proposed by \cite{regev2004quantum}. We briefly review the reduction idea here and refer the reader to \cite{regev2004quantum, brakerski2018learning} for details.

Let $(\bm{A}, \bm{b}_0 = \bm{As}_0 + \bm{e}_0)$ be a set of $m$ samples from $\lwe_{n, q, \alpha}$, written in matrix form. We start by preparing the state 
\[ \sum_{\bm{s} \in \Z_q^n} \sum_{j = 0}^{r - 1} \ket{j}\ket{\bm{s}}, \]
where we have dropped the normalization factors for simplicity. Here, $r$ is a function of $n$ and $q$. We then compute $(j, \bm{s}) \mapsto \bm{As} - j\bm{b}_0$ into an auxiliary register. After a change of variables we obtain the state
\begin{equation}
    \label{equ:latt-sup}
    \sum_{\bm{s} \in \Z_q^n} \sum_{j = 0}^{r - 1} \ket{j}\ket{\bm{s} + j\bm{s}_0}\ket{\bm{As} - j\bm{e}_0}.
\end{equation}
The goal is to project the above state onto a state $\sum_{\bm{s} \in \Z_q^n} \sum_{j = 0}^{r - 1} \ket{j}\ket{\bm{s} + j\bm{s}_0}$ for some $\bm{s} \in \Z_q^n$ with high probability. To do this, the idea is to draw $m$-dimensional balls around the points $\bm{As} - j\bm{e}_0$ for all $\bm{s} \in \Z_q^n$ and $j \in \Z_r$ and then select a random point in one of these balls. Let $\mathrm{B}_m(0, R)$ be a ball of radius $R$ around $0$. To implement the above idea, we can represent $\mathrm{B}_m(0, R)$ using points of a fine grid. More precisely, $\mathrm{B}_m(0, R)$ is represented by $\tilde{\mathrm{B}}_m(0, R) = \frac{1}{L} \Z^m \cap \mathrm{B}_m(0, R)$ for a large integer $L$. We can efficiently prepare (an approximation of) the superposition
\begin{equation}
    \label{equ:m-ball-sup}
    \ket{\tilde{\mathrm{B}}_m(0, R)} = \frac{1}{\sqrt{\tilde{\mathrm{B}}_m(0, R)}} \sum_{\bm{x} \in \tilde{\mathrm{B}}_m(0, R)} \ket{\bm{x}}.
\end{equation}
Note that for any $\bm{y} \in \Z_q^m$ we have $\bm{y} + \tilde{\mathrm{B}}_m(0, R) = \tilde{\mathrm{B}}_m(\bm{y}, R)$. Tensoring the states in \eqref{equ:latt-sup} and \eqref{equ:m-ball-sup} and adding the third register to the fourth register we obtain the state
\[ \sum_{\bm{s} \in \Z_q^n} \sum_{j = 0}^{r - 1} \ket{j}\ket{\bm{s} + j\bm{s}_0}\ket{\bm{As} - j\bm{e}_0}\ket{\tilde{\mathrm{B}}_m(\bm{As} - j\bm{e}_0, R)}. \]
For an appropriate choice of the radius $R$, for each $\bm{s} \in \Z_q^n$ the intersection $\cap_{j} \tilde{\mathrm{B}}_m(\bm{As} - j\bm{e}_0, R)$ is large, while $\tilde{\mathrm{B}}_m(\bm{As} - j\bm{e}_0, R) \cap \tilde{\mathrm{B}}_m(\bm{As}' - j'\bm{e}_0, R) = \emptyset$ for any $\bm{s} \ne \bm{s}'$ and any $j, j'$. Therefore, if we measure the last register we obtain the state
\[ \sum_{j = 0}^{r - 1} \ket{j}\ket{\bm{s} + j\bm{s}_0}\ket{\bm{As} - j\bm{e}_0} \]
for some random $\bm{s} \in \Z_q^n$, with probability $O(1 - 1 / \ell)$ where $\ell = \poly(n\log q)$. The last register can be uncomputed using the transform $\ket{j}\ket{\bm{x}}\ket{\bm{y}} \mapsto \ket{j}\ket{\bm{x}}\ket{\bm{y} - \bm{Ax} + j\bm{b}_0}$ to obtain the state $\sum_{j = 0}^{r - 1} \ket{j}\ket{\bm{s} + j\bm{s}_0}$.

The above procedure produces an $\edcp$ sample from $\lwe$ samples with a probability that is only polynomially close to $1$. This means we can obtain a polynomial number of $\edcp$ sample from a polynomial number of $\lwe$ samples, and that is the most we can do. In other words, producing a super-polynomial number of $\edcp$ samples from a super-polynomial number of $\lwe$ sample using the above procedure, can be done only with negligible probability. There is no known reduction from $\lwe$ to $\edcp$ for which the sample conversion probability is, for example, subexponentially close to $1$.


\subsection{Subexponential number of samples}
\label{sec:hardness-subexp}

When the number of samples is subexponential, $\edcp$ can be solved in time subexponential in $O(n\log q)$. This can be done using Kuperberg's algorithm \cite{kuperberg2005subexponential, kuperberg2011another}, which solves the hidden subgroup problem for the dihedral group $D_N$. The idea of the algorithm is to use a sieve on states of the form
\begin{equation}
    \label{equ:dih-coset}
    \frac{1}{\sqrt{2}}(\ket{0}\ket{x} + \ket{1}\ket{x + s}),
\end{equation}
where $x \in \Z_N$ is uniformly random, to recover the hidden shift $s \in \Z_N$. The state \eqref{equ:dih-coset} is called a dihedral coset state and the problem of recovering $s$, given such states, is called the Dihedral Coset Problem (DCP). The complexity of Kuperberg's algorithm is $2^{O(\sqrt{\log N})}$ for both time and space. Regev \cite{regev2004subexponential} improved the algorithm to use only $\poly(\log N)$ space at the cost of slightly increasing the running time to $2^{O(\sqrt{\log N \log\log N})}$.

Note that DCP is a special case of $\edcp_{n, q, r}$ where $n = 1$, $q = N$ and $r = 2$. Conversely, $\edcp$ can be reduced to vectorial variant of DCP which can be solved using a similar algorithm as in \cite{kuperberg2005subexponential}. We briefly explain the steps of the algorithm here.
\begin{theorem}
    \label{thm:subexp-smpl}
    Given $2^{O(\sqrt{n\log q})}$ samples, $\edcp_{n, q, r}$ can be solved in time $2^{O(\sqrt{n\log q})}$.
\end{theorem}
\begin{proof}
    Let $\bm{s} = (s_1, \dots, s_n)$. We will recover $s_n$, the rest of the $s_i$ can be recovered similarly. The proof proceeds in a sequence of simple reductions.
    \begin{enumerate}[leftmargin = *, font = \bfseries]
    \item From $\edcp_{n, q, r}$ to DCP over $\Z_q^n$: Given the distribution $\mu_{\bm{s}, r}$ we can efficiently sample from the distribution $\mu_{\bm{s}, 2}$ using Lemma \ref{lem:self-rd}. A sample from $\mu_{\bm{s}, 2}$ is of the form
    \[ \ket{\phi_{\bm{x}, 2}} = \frac{1}{\sqrt{2}}(\ket{0}\ket{\bm{x}} + \ket{1}\ket{\bm{x} + \bm{s}}), \]
    where $\bm{x} \in \Z_q^n$ is uniformly random. This is a dihedral coset state over the group $\Z_q^n$.
    \item From DCP over $\Z_q^n$ to DCP over $\Z_q$: measuring the second register of $(\mathds{1} \otimes \qft_{q^n}) \ket{\phi_{\bm{x}, 2}}$ we obtain the state
    \begin{equation}
        \label{equ:dih-coset-v}
        \ket{\phi_{\bm{y}}} = \frac{1}{\sqrt{2}}(\ket{0} + \omega_q^{\lrang{\bm{y}, \bm{s}}}\ket{1})
    \end{equation}
    where $\bm{y} \in \Z_q^n$ is the outcome of the measurement and is uniformly random. Given two such states $\ket{\phi_{\bm{y}_1}}$ and $\ket{\phi_{\bm{y}_2}}$, we can compute the state
    \[ \ket{\phi_{\bm{y}_1 - \bm{y}_2}} = \frac{1}{\sqrt{2}}(\ket{0} + \omega_q^{\lrang{\bm{y}_1 - \bm{y}_2, \bm{s}}}\ket{1}) \]
    with probability $1 / 2$ by measuring the second register of $\mathrm{CNOT} \ket{\phi_{\bm{y}_1}} \ket{\phi_{\bm{y}_2}}$. If $\bm{y}_1$ and $\bm{y}_2$ had the first $k$ coordinates in common then $\bm{y}_1 - \bm{y}_2$ would have $0$ in the first $k$ coordinates. From this, we can perform a sieve operation: prepare many states of the form \eqref{equ:dih-coset-v}, then pair the states that have $\bm{y}$ with the same first $k$ coordinates, and then perform the above operation to produce new states with $\bm{y}$ that have the first $k$ coordinates zeroed out. Repeating the same process on the new states produces states with $\bm{y}$ that have first $2k$ coordinates equal to $0$, and so on. The final output of this process is a state $\ket{\phi_{\bm{y}}}$ where $\bm{y} = (0, \dots, 0, y)$, i.e., the state
    \begin{equation}
        \label{equ:dih-sve}
        \ket{\phi_y} := \ket{\phi_{\bm{y}}} = \frac{1}{\sqrt{2}}(\ket{0} + \omega_q^{ys_n}\ket{1}).
    \end{equation}
    This is a DCP state over the group $\Z_q$.
    \item Kuperberg for DCP over $\Z_q$: From the states \eqref{equ:dih-sve} $s_n$ can be recovered using Kuperberg's algorithm.
    \end{enumerate}
    To analyze the above algorithm, suppose we start with $q^\ell$ states. Since we are zeroing out $k$ coordinates at each stage, there are $n / k$ stages. At any stage, if there are $c \cdot q^k$ states, it can be shown, using a simple application of Lemma \ref{lem:hoeffding}, that at least $c / 8 \cdot q^k$ states service the sieve operation. Therefore, to have $\Theta(q^k)$ states remaining in the last stage, we must have $q^\ell 8^{-n / k} \ge q^k$, hence $\ell \ge k + 3n / (k\log q)$. To minimize the right hand side, we take $k \in \Theta(\sqrt{n / \log q})$, and therefore, we can take $\ell \in \Theta(\sqrt{n / \log q})$.
\end{proof}
\begin{remark}
    When $q = \poly(n)$, Kuperberg's algorithm is not very efficient for solving DCP over $\Z_q$. Instead, we can use a POVM called the Pretty Good Measurement (PGM) \cite{hausladen1994pretty}. Suppose we have prepared the states $\ket{\phi_{y_0}}, \dots, \ket{\phi_{y_t}}$, of the form \eqref{equ:dih-sve}, for some $t \ge \lceil \log q \rceil + 1$. The tensor product of these states is
    \[ \ket{\psi} := \bigotimes_{j = 0}^{t - 1} \frac{1}{\sqrt{2}}(\ket{0} + \omega_q^{y_js_n}\ket{1}) = \frac{1}{\sqrt{2^t}} \sum_{x \in \{0, 1\}^t} \omega_q^{\alpha(x)s_n} \ket{x}, \]
    where $\alpha(x) = x_0y_0 + \cdots + x_ty_t \bmod q$. Using PGM on the state $\ket{\psi}$, we can recover $s_n$ with constant probability \cite{bacon2005optimal}. The implementation of PGM, in this case, boils down to inverting the function $\alpha: \{0, 1\}^t \rightarrow \Z_q$, which can be done efficiently since $q = \poly(n)$.   
\end{remark}





%% ///////////////////////////////////////////////////////



\bibliographystyle{plain}
\bibliography{references}




%% ///////////////////////////////////////////////////////



\newpage
\appendix

\section{Poisson Summation}
Let $G$ be a locally compact abelian group, and let $\mathbb{T}$ be the circle group. The dual group $\hom(G, \mathbb{T})$ of all continuous group homomorphisms from $G$ to $\mathbb{T}$ is denoted by $\widehat{G}$. The operation in $\widehat{G}$ is pointwise multiplication, i.e., for $\chi_1, \chi_2 \in \widehat{G}$, $(\chi_1 . \chi_2)(x) = \chi_1(x)\chi_2(x)$. There is a natural topology on $\widehat{G}$, called the compact-open topology, that makes it a topological group. It can be shown that $\widehat{G}$ is a locally compact abelian group as well. In the representation theory language, $\widehat{G}$ is called the character group of $G$ and the element of $\widehat{G}$ are called characters. 

The group $G$ carries a Haar measure that unique up to a multiplicative positive constant. The space $L^1(G)$ is then defined according to the Haar measure. For a character $\chi \in \widehat{G}$, the Fourier transform of a function $f \in L^1(G)$ is defined by the Haar integral
\[ \hat{f}(\chi) = \int_{G} f(g)\overline{\chi(g)} dg. \]
Let $H \le G$ be a closed subgroup, so there is an exact sequence
\begin{equation}
    \label{equ:ses}
    0 \rightarrow H \rightarrow G \rightarrow G / H \rightarrow 0
\end{equation}
of topological groups. Applying the functor $\hom(-, \mathbb{T})$ to the above sequence, we obtain the exact sequence
\begin{equation}
    \label{equ:d-ses}
    0 \rightarrow \widehat{G / H} \rightarrow \widehat{G} \rightarrow \widehat{H} \rightarrow 0
\end{equation}
of duals. The Fourier transform is a linear map from the groups in \eqref{equ:ses} to the groups in \eqref{equ:d-ses}. The Poisson summation formula relates these Fourier transforms. We can always choose Haar measures on $H, G$, and $G / H$ such that the quotient integral identity
\[ \int_G f(g) dg = \int_{G / H} \int_H f(gh) dh d(gH) \]
holds for every compactly supported continuous function $f: G \rightarrow \C$.
\begin{theorem}[Poisson summation]
    \label{thm:poisson-sum}
    Let $H \le G$ be a closed subgroup and let $f \in L^1(G)$. Define $f_H \in L^1(G / H)$ by $f_H(gH) = \int_H f(gh) dh$. Then $\widehat{f_H} = \hat{f} \vert_{\widehat{G / H}}$, where $\vert$ is restriction. If $\hat{f} \vert_{\widehat{G / H}} \in L^1(\widehat{G / H})$ then we also have
    \[ \int_{H} f(gh) dh = \int_{\widehat{G / H}} \hat{f}(\chi) \chi(g) d\chi \]
    for almost all $g \in G$.
\end{theorem}
An example of a locally compact group is $G = \R^n$ with Haar measure taken to be the usual Lebesgue measure. For each $\bm{u} \in \R^n$ the mapping $\chi_{\bm{u}}: \R^n \rightarrow \C$ defined by $\chi_{\bm{u}}(\bm{x}) = e^{2\pi i \lrang{\bm{u}, \bm{v}}}$ is a character of $G$. In fact, all the elements of $\widehat{G}$ are of this form, and we have $\R^n \simeq \widehat{\R^n}$ via the map $\bm{u} \mapsto \chi_{\bm{u}}$. Let $H = L$ where $L$ is a lattice. Then since $L$ and $\widehat{\R^n / L} = L^\perp$ are both discrete groups, the integrals in Theorem \ref{thm:poisson-sum} are just summations, so we obtain
\[ \sum_{\bm{x} \in L} f(\bm{x} + \bm{y}) = \frac{1}{\mathrm{Vol}(\R^n / L)}\sum_{\bm{x} \in L^\perp} \hat{f}(\bm{x})e^{2\pi i \lrang{\bm{x}, \bm{y}}}  \]
\end{document}



